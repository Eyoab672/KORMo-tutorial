{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e5e86a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6645cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acac63272f56471c9f45d30e449afd89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/895 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9d63c611c5f444597e0567966333325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_configuration_kormo.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/KORMo-Team/KORMo-10B-base:\n",
      "- _configuration_kormo.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ace84551fffb44f8b2eaf6417d51ad8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_modeling_kormo.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/KORMo-Team/KORMo-10B-base:\n",
      "- _modeling_kormo.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "052eb459c68249ee9abd33e286823204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b96a24e680645a5aae3656af7fdf84f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00005.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(MaxRetryError(\"HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Max retries exceeded with url: /xet-bridge-us/68ea8d6315ff98c4d4233929/7964b6812d1403c01fefa9cd30198cf113e7f71ace3c1d2644008812c6002873?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251012%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251012T082912Z&X-Amz-Expires=3600&X-Amz-Signature=af9657a3babb02f9e6db5a0fa5cb4f3549a4393b3834dd818385ac6327d5ffaa&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=6435a57b2d0ed796668d8a3f&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00002-of-00005.safetensors%3B+filename%3D%22model-00002-of-00005.safetensors%22%3B&x-id=GetObject&Expires=1760261352&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2MDI2MTM1Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82OGVhOGQ2MzE1ZmY5OGM0ZDQyMzM5MjkvNzk2NGI2ODEyZDE0MDNjMDFmZWZhOWNkMzAxOThjZjExM2U3ZjcxYWNlM2MxZDI2NDQwMDg4MTJjNjAwMjg3MyoifV19&Signature=Mt2NXjocfoHG~zPklAZyYiGq9LEW-FOLUP~klabyfNGdk0nVDygn7QHCUHc491xIkdS2JYkxzSSQAryZ1rkhpqeh1EbiQL67u0B5RO1C~7rLxwS2q1cJ5CHnGIRd6YNXg0MW0cRo8Zo6wNowedxsCCBz3xbvDet-gOz0rESsKzxQ~U2yx9BocbdwAcGN0ESPwycIzmUf5U-dUQ0x0JH4-LRBD0g8h2KV7K5DqN0i1j3OeFeu0e~S4KJdbo3wcrPdgNV~X43wgS~UaQgU4D1GE3fIscOyAGe6dT7VZ52BH4pUxh~uP~pvknVPhrXr2Tm1hYKJXyilMU2ZyBDE2SH5OA__&Key-Pair-Id=K2L8F4GPSG1IFC (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1010)')))\"), '(Request ID: 0a7cf3f3-9fe0-4b41-af80-c0904854bbef)')' thrown while requesting GET https://huggingface.co/KORMo-Team/KORMo-10B-base/resolve/cd2ad386d2e06a3e20e07f01dd18ff0e55e3432e/model-00002-of-00005.safetensors\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba70c747d400416c80179dbc814e1714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00005.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf0918e5c0b941a1badc15c179d9aaa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00005.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31b32a4531944ee294417088644cddb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00005.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c94f1cac89694b3a8d093479e21446a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00005.safetensors:   0%|          | 0.00/1.65G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "961adcae5d304d00a49fe4b2316cd2ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c73984443384f8d8a9a1f4824dee654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/121 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "repo_id = \"KORMo-Team/KORMo-10B-base\"\n",
    "tokenizer_repo_id = \"KORMo-Team/KORMo-tokenizer\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    repo_id,\n",
    "    dtype='bfloat16',\n",
    "    trust_remote_code=True,\n",
    ").to('cuda')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_repo_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "99f18b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:125031 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|BOS|>dynamic sampling처럼, passrate = 0 or 1을 제외하고, rollout 안에 정답/오답이 고루 분포하는 데이터를 뽑아서 가지고있어.\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.metrics import accuracy_score\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from sklearn.metrics import classification_report\n",
      "from sklearn.metrics import precision_score\n",
      "from sklearn.metrics import recall_score\n",
      "from sklearn.metrics import f1_score\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "from sklearn.metrics import\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\"dynamic sampling처럼, passrate = 0 or 1을 제외하고, rollout 안에 정답/오답이 고루 분포하는 데이터를 뽑아서 가지고있어.\", return_tensors='pt').to(model.device)\n",
    "outputs = model.generate(**inputs, max_new_tokens=1024, do_sample=False)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_kormo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
